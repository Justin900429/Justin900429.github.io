---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# About Me

My current research lies at the intersection of generative modeling, multimodal AI, and visual reasoning, with a particular focus on diffusion-based models and their applications in computer vision.

I completed my **Bachelorâ€™s degree in Electrical and Computer Engineering** at [National Yang Ming Chiao Tung University](https://www.nycu.edu.tw/nycu/en/index), where I am now continuing my journey as a **Ph.D. candidate**.

## ğŸ“ Publications

- Score Replacement with Bounded Deviation for Rare Prompt Generation \\
  ğŸª¶ **Bo-Kai Ruan**, Zi-Xiang Ni, Bo-Lun Huang, Teng-Fang Hsiao, Hong-Han Shuai \\
  ğŸŒ *Preprint 2025* \\
  **One-liner**: Adaptive switching from frequent to rare prompt for rare concept generation \\
  [[Paper](https://arxiv.org/abs/2505.20808)]
- Ranking-based Preference Optimization for Diffusion Models from Implicit User Feedback \\
  ğŸª¶ Yi-Lun Wu, **Bo-Kai Ruan**, Chiang Tseng, Hong-Han Shuai \\
  ğŸŒ In *Neural Information Processing Systems (**NeurIPS**) 2025* \\
  **One-liner**: Preference optimization requires with preferred data only
- Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation \\
  ğŸª¶ Sung-Lin Tsai, Bo-Lun Huang, Yu Ting Shen, Cheng Yu Yeo, Chiang Tseng, **Bo-Kai Ruan**, Wen-Sheng Lien, Hong-Han Shuai \\
  ğŸŒ In *ACM International Conference on Multimedia (**ACM MM**) 2025* \\
  **One-liner**: Color embeddings can be represented by text embeddings \\
  [[Paper](https://arxiv.org/abs/2509.10058)]
- TF-TI2I: Training-Free Text-and-Image-to-Image Generation via Multi-Modal Implicit-Context Learning in Text-to-Image Models \\
  ğŸª¶ Teng-Fang Hsiao, **Bo-Kai Ruan**, Yi-Lun Wu, Tzu-Ling Lin, Hong-Han Shuai \\
  ğŸŒ In *International Conference on Computer Vision (**ICCV**) 2025* \\
  **One-liner**: Image features are text features within MM-DiT \\
  [[Paper](https://arxiv.org/abs/2503.15283)] [[Code](https://github.com/BlueDyee/TF-TI2I)] [[Project Page](https://bluedyee.github.io/TF-TI2I_page)]
- MAD: Makeup All-in-One with Cross-Domain Diffusion Model \\
  ğŸª¶ **Bo-Kai Ruan**, Hong-Han Shuai \\
  ğŸŒ In *Conference on Computer Vision and Pattern Recognition Workshop (**CVPRW**) 2025* \\
  **One-liner**: All makeup tasks are domain transfer tasks \\
  [[Paper](https://arxiv.org/abs/2504.02545)] [[Code](https://github.com/basiclab/MAD)] [[Project Page](https://basiclab.github.io/MAD/)]
- Training-and-Prompt-Free General Painterly Harmonization via Zero-Shot Disentenglement on Style and Content References \\
  ğŸª¶ Teng-Fang Hsiao, **Bo-Kai Ruan**, Hong-Han Shuai \\
  ğŸŒ In *AAAI Conference on Artificial Intelligence (**AAAI**) 2025* \\
  **One-liner**: Painterly harmonization is to add contents but preserve style \\
  [[Paper](https://arxiv.org/abs/2404.12900)] [[Code](https://github.com/BlueDyee/TF-GPH)]
- Modeling Uncertainty for Low-Resolution Facial Expression Recognition \\
  ğŸª¶ Ling Lo, **Bo-Kai Ruan**, Hong-Han Shuai, Wen-Huang Cheng \\
  ğŸŒ *IEEE Transactions on Affective Computing (**T-AC**) 2023* \\
  **One-liner**: Caring low-resolution facial expression recognition with uncertainty \\
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10098204)]
- Mimicking the Annotation Process for Recognizing the Micro Expressions \\
  ğŸª¶ **Bo-Kai Ruan**, Ling Lo, Hong-Han Shuai, Wen-Huang Cheng \\
  ğŸŒ In *ACM International Conference on Multimedia (**ACM MM**) 2022* \\
  **One-liner**: Training the model to recognize expressions like how we do \\
  [[Paper](https://basiclab.lab.nycu.edu.tw/assets/MAP-MER.pdf)] [[Code](https://github.com/Justin900429/mimicking-annotation-micro-expression-recognition)]

More can be found in [my Google Scholar Page](https://scholar.google.com/citations?user=1-BrMaAAAAAJ).

## ğŸŒŸ Services

### Conference Reviewers

- Neural Information Processing Systems (NeurIPS), *2025*
- International Conference on Learning Representations (ICLR), *2024-2025*
- AAAI Conference on Artificial Intelligence (AAAI), *2025*
- ACM International Conference on Multimedia (ACM MM), *2023-2025*
- IEEE International Conference on Multimedia (ICME), *2023-2024*

### Journal Reviewers

- IEEE Transactions on Multimedia (T-MM)

## ğŸ“ Educations

- *2023 - Present*, ECE PhD, National Yang Ming Chiao Tung University, Taiwan
- *2019 - 2023*, ECE Undergraduate, National Yang Ming Chiao Tung University, Taiwan
