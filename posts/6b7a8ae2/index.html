<!DOCTYPE html>
<html lang="en">
    <head>
    <meta charset="utf-8">

    

    <!-- 渲染优化 -->
    <meta name="renderer" content="webkit">
    <meta name="force-rendering" content="webkit">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="HandheldFriendly" content="True" >
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <!--icon-->

    
    
    
        <link rel="icon" type="image/png" sizes="32x32" href="/icon.png">
    
    
        <link rel="apple-touch-icon" sizes="180x180" href="/apple_icon_128.png">
    
    
        <link rel="mask-icon" href="/apple_icon_128.png">
    


    <!-- meta -->


<title>[Series - 13] Regression - 2 | Justin</title>


    <meta name="keywords" content="OpenCV,MachineLearning, Android, AI, Algorithm, DataStructure">




    <!-- OpenGraph -->
 
    <meta name="description" content="[Series - 13] Regression - 2See moreBack to the series page   前言上篇已經介紹完 Regression 的應用。今天我們就來實際看看其背後的數學邏輯！ NotebookNotebook 符號說明今天所有推導都會直接利用高維，也就是說會利用 Multinomial Regression. 昨天說到 Multinomial Regressi">
<meta property="og:type" content="article">
<meta property="og:title" content="[Series - 13] Regression - 2">
<meta property="og:url" content="justin900429.github.io/posts/6b7a8ae2/index.html">
<meta property="og:site_name" content="Justin">
<meta property="og:description" content="[Series - 13] Regression - 2See moreBack to the series page   前言上篇已經介紹完 Regression 的應用。今天我們就來實際看看其背後的數學邏輯！ NotebookNotebook 符號說明今天所有推導都會直接利用高維，也就是說會利用 Multinomial Regression. 昨天說到 Multinomial Regressi">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.imgur.com/Fz10no8.jpg">
<meta property="og:image" content="https://i.imgur.com/uwoj1I1.jpg">
<meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/1*9sd4Ve9DH-k4EcNba5fGTA.jpeg">
<meta property="og:image" content="https://i.imgur.com/wdXaaEh.jpg">
<meta property="article:published_time" content="2020-08-31T13:19:31.000Z">
<meta property="article:modified_time" content="2021-01-01T02:30:21.978Z">
<meta property="article:author" content="Justin Ruan">
<meta property="article:tag" content="OpenCV,MachineLearning, Android, AI, Algorithm, DataStructure">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://i.imgur.com/Fz10no8.jpg">


    
<link rel="stylesheet" href="/css/style/main.css">
 



    
    
    
        <link rel="stylesheet" id="hl-default-theme" href="https://cdn.jsdelivr.net/npm/highlight.js@10.1.2/styles/atom-one-light.min.css" media="none" onload="if(getComputedStyle(document.documentElement).getPropertyValue('--color-mode').indexOf('dark')===-1)this.media='all'">
        
    

    

     

    <!-- custom head -->

<meta name="generator" content="Hexo 5.1.1"></head>

    <body>
        <div id="app">
            <header class="header">
    <div class="header__left">
        <a href="/" class="button">
            <span class="logo__text">Justin&#39;s blog</span>
        </a>
    </div>
    <div class="header__right">
        
            <div class="navbar__menus">
                
                    <a href="/about/" class="navbar-menu button">Home</a>
                
                    <a href="/about/resume.pdf" class="navbar-menu button">CV</a>
                
                    <a href="/" class="navbar-menu button">Articles</a>
                
                    <a href="/tags/" class="navbar-menu button">Tags</a>
                
                    <a href="/archives/" class="navbar-menu button">Archives</a>
                
            </div>
        
        
        
    <a href="/search/" id="btn-search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="24" height="24" fill="currentColor" stroke="currentColor" stroke-width="32"><path d="M192 448c0-141.152 114.848-256 256-256s256 114.848 256 256-114.848 256-256 256-256-114.848-256-256z m710.624 409.376l-206.88-206.88A318.784 318.784 0 0 0 768 448c0-176.736-143.264-320-320-320S128 271.264 128 448s143.264 320 320 320a318.784 318.784 0 0 0 202.496-72.256l206.88 206.88 45.248-45.248z"></path></svg>
    </a>


        
        

         
    <a href="#" class="button" id="b2t" aria-label="Back to Top" title="Back to Top">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="32" height="32">
            <path d="M233.376 722.752L278.624 768 512 534.624 745.376 768l45.248-45.248L512 444.128zM192 352h640V288H192z" fill="currentColor"></path>
        </svg>
    </a>


        
            <a class="dropdown-icon button" id="btn-dropdown" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width='24' height='24' fill="none" stroke="currentColor" stroke-width="0.7" stroke-linecap="round" stroke-linejoin="round"><path fill="currentColor" d="M3.314,4.8h13.372c0.41,0,0.743-0.333,0.743-0.743c0-0.41-0.333-0.743-0.743-0.743H3.314c-0.41,0-0.743,0.333-0.743,0.743C2.571,4.467,2.904,4.8,3.314,4.8z M16.686,15.2H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,15.2,16.686,15.2z M16.686,9.257H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,9.257,16.686,9.257z"></path></svg></a>
            <div class="dropdown-menus" id="dropdown-menus">
                
                    <a href="/about/" class="dropdown-menu button">Home</a>
                
                    <a href="/about/resume.pdf" class="dropdown-menu button">CV</a>
                
                    <a href="/" class="dropdown-menu button">Articles</a>
                
                    <a href="/tags/" class="dropdown-menu button">Tags</a>
                
                    <a href="/archives/" class="dropdown-menu button">Archives</a>
                
            </div>
        
    </div>
</header>


            <main class="main">
    

<div class="post-title">
    <h1 class="post-title__text">
        [Series - 13] Regression - 2
    </h1>
    <div class="post-title__meta">
        <a href="/archives/2020/08/" class="post-meta__date button">2020-08-31</a>
        
 
        
    
    


 

 
    </div>
</div>


    <aside class="post-side">
        <div class="post-side__toc">
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Notebook"><span class="toc-number">2.</span> <span class="toc-text">Notebook</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%A6%E8%99%9F%E8%AA%AA%E6%98%8E"><span class="toc-number">3.</span> <span class="toc-text">符號說明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-descent"><span class="toc-number">4.</span> <span class="toc-text">Gradient descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2D"><span class="toc-number">4.1.</span> <span class="toc-text">2D</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#General"><span class="toc-number">4.2.</span> <span class="toc-text">General</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-of-regression"><span class="toc-number">5.</span> <span class="toc-text">Gradient of regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%A6%E4%BD%9C-Linear-Regression"><span class="toc-number">6.</span> <span class="toc-text">實作 Linear Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%B5%90"><span class="toc-number">7.</span> <span class="toc-text">小結</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">8.</span> <span class="toc-text">Reference</span></a></li></ol>
        </div>
    </aside>
    <a class="btn-toc button" id="btn-toc" tabindex="0">
        <svg viewBox="0 0 1024 1024" width="32" height="32" xmlns="http://www.w3.org/2000/svg">
            <path d="M128 256h64V192H128zM320 256h576V192H320zM128 544h64v-64H128zM320 544h576v-64H320zM128 832h64v-64H128zM320 832h576v-64H320z" fill="currentColor"></path>
        </svg>
    </a>
    <div class="toc-menus" id="toc-menus">
        <div class="toc-title">Article Directory</div>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Notebook"><span class="toc-number">2.</span> <span class="toc-text">Notebook</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%A6%E8%99%9F%E8%AA%AA%E6%98%8E"><span class="toc-number">3.</span> <span class="toc-text">符號說明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-descent"><span class="toc-number">4.</span> <span class="toc-text">Gradient descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2D"><span class="toc-number">4.1.</span> <span class="toc-text">2D</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#General"><span class="toc-number">4.2.</span> <span class="toc-text">General</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-of-regression"><span class="toc-number">5.</span> <span class="toc-text">Gradient of regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%A6%E4%BD%9C-Linear-Regression"><span class="toc-number">6.</span> <span class="toc-text">實作 Linear Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%B5%90"><span class="toc-number">7.</span> <span class="toc-text">小結</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">8.</span> <span class="toc-text">Reference</span></a></li></ol>
    </div>


<article class="post content-card">
    <div class="post__header"></div>
    <div class="post__content">
        <h1 id="Series-13-Regression-2"><a href="#Series-13-Regression-2" class="headerlink" title="[Series - 13] Regression - 2"></a>[Series - 13] Regression - 2</h1><blockquote class="blockquote-note blockquote-note__tip"><div class="blockquote-note__header"><div class="blockquote-note__icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></div>See more</div><div class="blockquote-note__content"><p><a href="/posts/f9a1d882/">Back to the series page</a></p>
</div></blockquote>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上篇已經介紹完 Regression 的應用。今天我們就來實際看看其背後的數學邏輯！</p>
<h2 id="Notebook"><a href="#Notebook" class="headerlink" title="Notebook"></a>Notebook</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://colab.research.google.com/github/Justin900429/IT-used/blob/master/Regression.ipynb">Notebook</a></p>
<h2 id="符號說明"><a href="#符號說明" class="headerlink" title="符號說明"></a>符號說明</h2><p>今天所有推導都會直接利用高維，也就是說會利用 <strong>Multinomial Regression</strong>. 昨天說到 <strong>Multinomial Regression</strong> 的數學形式長這樣：</p>
<p>$$<br>f(x_{1}, x_{2}, …, x_{n}) = x_{1}\theta_{1} + x_2\theta_{2} + … + x_n\theta_{n}<br>$$</p>
<p>每次都要這樣寫有些麻煩，而且不易閱讀，因此我們可以採用矩陣的寫法：</p>
<p>$$<br>X = (x_1, x_2, … x_n)^T \in R^n<br>$$<br>$$<br>\theta = (\theta_1, \theta_2, …,\theta_n)^T \in R^n<br>$$<br>$$<br>f(X) = \sum_{i = 1}^{n}\theta_ix_i = \theta^TX<br>$$</p>
<p>其中 $X$是我們的資料，$\theta$則是我們要訓練的參數。</p>
<h2 id="Gradient-descent"><a href="#Gradient-descent" class="headerlink" title="Gradient descent"></a>Gradient descent</h2><p><strong>Gradient descent</strong> 是一個非常重要的數學工具，基本上主導了很多機器學習的演算法。我們之前提到說要找到最好的解就是要<strong>最小化 Loss function</strong>。既然是 function，就會有其對應的圖形，我們先來看二維的。</p>
<h3 id="2D"><a href="#2D" class="headerlink" title="2D"></a>2D</h3><p>假設我們的直線是 $f(x)=\theta x$、<strong>Loss function</strong> 是 $L(\theta)=\frac{1}{2}\sum_{i= 1}^{m}(x^{(i)}\theta  - y^{(i)})^2$（$m$ 代表有 $m$ 筆資料, ($x^{(i)}$, $y^{(i)}$) 則是第 i 筆資料），圖形爲為二次方(下圖為示意圖):</p>
<p><img src="https://i.imgur.com/Fz10no8.jpg"></p>
<p>我們的目標是想要找到 $\theta$ 使得 $L(\theta)$ 最小，但是我們必須記住，$\theta$ 隨時都在改變，我們不會一次就找到最小的點，只能透過現在 $\theta$ 的值來優化我們的<strong>Loss function</strong>。想要找最小的值我們就是透過<strong>微分</strong>來找。微分後所得到的值是變化 $x$ 所得到的 $y$ 值，方向則是會想要往值大的地方跑，大家可以嘗試看看。</p>
<blockquote>
<p>左半邊的微分都為正值，因此 $\theta + d\theta$ 得到的值會使 $L$ 變大; 右半邊的微分為負，但是 $\theta + d\theta$ 得到的值也會使 $L$ 變大（右半 $d\theta$ 為負）</p>
</blockquote>
<p>現在我們想要使得$L$最小，因此我們在更新 $\theta$ 應該用<strong>減的</strong>。另外，一次走大步跟走小步的效果也會有差，因此我們可以用 $\alpha$ 來表示更新的距離。因此 $\theta$ 的更新方式應該是:</p>
<p>$$<br>    \theta^{n+1} = \theta^{n} - \alpha * \frac{dL(\theta)}{d \alpha}<br>$$</p>
<p>希望這張圖能讓大家知道 $\alpha$ 的影響。另外，如果 $\alpha$ 設太大則會造成無法收斂，如果下圖設成 2，則會在 1, -1 來回震盪。但若太小，收斂速度非常慢。</p>
<p>基本上不太可能跑一次就收斂，因此我們也需要跑很多次 <strong>Gradient descent</strong> 來找到最佳解。</p>
<p><img src="https://i.imgur.com/uwoj1I1.jpg"></p>
<p>這是三維的：<br><img src="https://cdn-images-1.medium.com/max/1200/1*9sd4Ve9DH-k4EcNba5fGTA.jpeg"><br>目標都是希望可以走到低點 B</p>
<h3 id="General"><a href="#General" class="headerlink" title="General"></a>General</h3><p>現在我們拓展我們的維度到 n 維，對於每一個 $\theta_j$，其更新方式也是一樣，只不過其他的$\theta_{k}$就要視為常數:</p>
<p>$$<br>\theta_j^{n+1} = \theta_j^{n} - \alpha * \frac{\partial L(\theta)}{\partial \theta_j}<br>$$</p>
<p>這邊我們可以直接用:</p>
<p>$$<br>\theta^{n+1} = \theta^{n} - \alpha * \nabla L(\theta)<br>$$</p>
<p>來更新所有 $\theta_k$。</p>
<p>這邊我們說明完如何透過極小化 <strong>Loss function</strong> 來找到最佳解，以後也會有很多演算法用到<strong>Gradient decent</strong>！</p>
<h2 id="Gradient-of-regression"><a href="#Gradient-of-regression" class="headerlink" title="Gradient of regression"></a>Gradient of regression</h2><p>我們現在就來找出 <strong>Regression</strong> 的 <strong>gradient</strong> 吧!</p>
<p>$$<br>\text{Target function}: \  \hat y = h_\theta(X) = \theta^TX<br>$$<br>$$<br>\text{Loss function}: \  L(\theta) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(X^{(i)}) - y^{(i)})^2<br>$$<br>$$<br>\begin{align}<br>\frac{\partial}{\partial \theta_j}L(\theta) &amp;= \sum_{i=1}^{m}(h_\theta(X^{(i)}) - y^{(i)})\frac{\partial}{\partial \theta_j}(\sum_{j=1}^{n}\theta_jx_j - y^{(i)}) \\<br>&amp;= \sum_{i=1}^{m}(y^{(i)} - h_\theta(X^{(i)}))x_j<br>\end{align}<br>$$</p>
<p>現在我們已經找到更新的方式了，代表我們可以自己實作 <strong>Linear Regression</strong>了。</p>
<h2 id="實作-Linear-Regression"><a href="#實作-Linear-Regression" class="headerlink" title="實作 Linear Regression"></a>實作 Linear Regression</h2><p>這部分就是要利用 <strong>Gradient descent</strong> 來做 <strong>Linear Regression</strong>。雖然這邊只有實作 <strong>Linear</strong> 的，但是高維的方式都是一樣的！</p>
<pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gradient_descent</span>(<span class="hljs-params">X, y, theta, alpha, num_iters</span>):</span>
    <span class="hljs-string">&#x27;&#x27;&#x27;</span>
<span class="hljs-string">    input:</span>
<span class="hljs-string">        X: data (2D array)</span>
<span class="hljs-string">        y: labels for each data (1D array)</span>
<span class="hljs-string">        theta: param (1D array)</span>
<span class="hljs-string">        alpha: learning rate (int)</span>
<span class="hljs-string">        num_iters: total iterations to update theta (int)</span>
<span class="hljs-string">    </span>
<span class="hljs-string">    Target:</span>
<span class="hljs-string">        This function is used to update theta by gradient descent</span>
<span class="hljs-string">    </span>
<span class="hljs-string">    return:</span>
<span class="hljs-string">        theta: Final parameters(1D array)</span>
<span class="hljs-string">        J_history: Loss function of each history (2D array)  </span>
<span class="hljs-string">    &#x27;&#x27;&#x27;</span>
    <span class="hljs-comment"># Get the cost of lost function in each iteration</span>
    J_history = np.zeros(num_iters)
    
    <span class="hljs-comment"># Start gradient descent</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, num_iters):
        grad = np.dot(X, theta.T) - y
        grad = np.multiply(X.T, grad).T
        grad = np.mean(grad, axis=<span class="hljs-number">0</span>)
        
        theta = theta - alpha * grad

        J_history[i] = compute_cost(X, y, theta)

    <span class="hljs-keyword">return</span> theta, J_history


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_cost</span>(<span class="hljs-params">X, y, theta</span>):</span>
    <span class="hljs-string">&#x27;&#x27;&#x27;</span>
<span class="hljs-string">    Input:</span>
<span class="hljs-string">        X: numpy array</span>
<span class="hljs-string">        y: labels</span>
<span class="hljs-string">    </span>
<span class="hljs-string">    Use:</span>
<span class="hljs-string">        Get the cost of loss function</span>
<span class="hljs-string">        </span>
<span class="hljs-string">    Return</span>
<span class="hljs-string">        Loss for each iteration (Int)</span>
<span class="hljs-string">    &#x27;&#x27;&#x27;</span>
    cost = y - np.dot(X, theta.T)
    cost = cost * cost
    cost = cost / <span class="hljs-number">2</span>

    <span class="hljs-keyword">return</span> np.mean(cost)</code></pre>

<p>細節都在程式碼裡，至於結果就放在 Colab notebook 裡，這裡要注意一點：</p>
<pre><code class="hljs python"><span class="hljs-comment"># Add a column of ones to x</span>
X = np.c_[np.ones(y.shape[<span class="hljs-number">0</span>]), x]</code></pre>
<p>這行的用意是為了加入<strong>截距</strong>：<br>$$<br>f(x) = mx_1 + b \ \rightarrow<br>f(x) = \theta_1x_1 + \theta_2x_2 \ \ \ \ where \ \theta_2 = b, x_2 = 1<br>$$</p>
<p><img src="https://i.imgur.com/wdXaaEh.jpg"></p>
<p>讀者也可以將資料提升到高維，直接丟入我們的函數也沒問題！</p>
<h2 id="小結"><a href="#小結" class="headerlink" title="小結"></a>小結</h2><p>今天講的東西可能有些複雜，如果有任何問題或是我有寫錯的話歡迎大家在下面跟我一起討論！另外，我在 <strong>Gradient descent</strong> 講的東西有些少，例如討論<strong>learning rate</strong> 太大或太小造成的問題等等…明天還是數學的一天，請大家<del>期待</del>～</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://cs229.stanford.edu/">CS229 from Standford</a></li>
</ol>
<br/>
<br/>
<a href="/posts/75d5101b/" float=left>Last</a> <a href="/posts/3cefc63f/" style="float: right;">Next</a><!-- flag of hidden posts -->
    </div>
     
    <div class="post-footer__meta"><p>updated at 2021-01-01</p></div> 
    <div class="post-meta__cats"></div> 
</article>




    <div class="post__comments content-card" id="comment">
        
    <h4>Comments</h4>
    
    <div id="disqus_thread">Unable to load Disqus, please make sure your network can access.</div>

    
    
    
    
    
    
    
    
    


    </div>



</main>

            <footer class="footer">
    
        <script src='https://cdnjs.cloudflare.com/ajax/libs/viz.js/1.7.1/viz.js'></script>
        <script>
          String.prototype.replaceAll = function(search, replacement) {
            var target = this;
            return target.split(search).join(replacement);
          };
      
          let vizObjects = document.querySelectorAll('.graphviz')
      
          for (let item of vizObjects) {
            let svg = undefined
            try {
              svg = Viz(item.textContent.replaceAll('–', '--'), 'svg')
            } catch(e) {
              svg = `<pre class="error">${e}</pre>`
            }
            item.outerHTML = svg
          }
        </script>
    
    


    
     
 

 
    
        
        <p class="footer-copyright">
            Copyright © 2021 <a href="/">Justin</a>
        </p>
    
    
    <p>Powered by <a href="https://hexo.io" rel="external nofollow noreferrer" target="_blank">Hexo</a> | Theme - <a href="https://github.com/ChrAlpha/hexo-theme-cards" rel="external nofollow noreferrer" target="_blank">Cards</a></p>
</footer>

        </div>
         

 

 

 

  



 


    
 

 


    <script>
        if (typeof MathJax === 'undefined') {
            window.MathJax = {
                loader: {
                    source: {
                        '[tex]/amsCd': '[tex]/amscd',
                        '[tex]/AMScd': '[tex]/amscd'
                    }
                },
                tex: {
                    inlineMath: [['$', '$'], ['\\(', '\\)']],
                },
                options: {
                    renderActions: {
                        findScript: [10, doc => {
                            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                                const display = !!node.type.match(/; *mode=display/);
                                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                                const text = document.createTextNode('');
                                node.parentNode.replaceChild(text, node);
                                math.start = {node: text, delim: '', n: 0};
                                math.end = {node: text, delim: '', n: 0};
                                doc.math.push(math);
                            });
                        }, '', false],
                        insertedScript: [200, () => {
                            document.querySelectorAll('mjx-container').forEach(node => {
                                let target = node.parentNode;
                                if (target.nodeName.toLowerCase() === 'li') {
                                    target.parentNode.classList.add('has-jax');
                                }
                            });
                        }, '', false]
                    }
                }
            };
            (function () {
                var script = document.createElement('script');
                script.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
                script.defer = true;
                document.head.appendChild(script);
            })();
        } else {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
        }
    </script>
 

 

 


    
    <script>
        function loadComment() {
            window.disqus_config = function () {
                this.page.url = 'justin900429.github.io/posts/6b7a8ae2/';
                this.page.identifier = 'posts/6b7a8ae2/';
            };
            (function(){
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + 'https-justin900429-github-io' + '.disqus.com/embed.js';
                (document.head || document.body).appendChild(dsq);
            })();
        }
    
        var runningOnBrowser = typeof window !== "undefined";
        var isBot = runningOnBrowser && !("onscroll" in window) || typeof navigator !== "undefined" && /(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent);
        var supportsIntersectionObserver = runningOnBrowser && "IntersectionObserver" in window;
    
        setTimeout(function () {
            if (!isBot && supportsIntersectionObserver) {
                var comment_observer = new IntersectionObserver(function(entries) {
                    if (entries[0].isIntersecting) {
                        loadComment();
                        comment_observer.disconnect();
                    }
                }, { threshold: [0] });
                comment_observer.observe(document.getElementById('comment'));
            } else {
                loadComment();
            }
        }, 1);
    </script>


    
    
    

    
    
    
    
    

    
    
    
    
    

    



    </body>
</html>
