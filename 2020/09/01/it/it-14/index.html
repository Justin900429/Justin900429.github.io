<!DOCTYPE html>
<html lang="en">
    <head>
    <meta charset="utf-8">

    

    <!-- 渲染优化 -->
    <meta name="renderer" content="webkit">
    <meta name="force-rendering" content="webkit">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="HandheldFriendly" content="True" >
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <!--icon-->

    <link rel="shortcut icon" type='image/x-icon' href="/mylogo.ico">


    <!-- meta -->


<title>[Series - 14] Regression - 3 | Justin</title><meta name="robots" content="noindex">





    <!-- OpenGraph -->
 
    <meta name="description" content="[Series - 14] Regression - 3See moreBack to the series page   前言今天會延續上篇的部分，繼續做一些推導，並且引進 Maximun likelihood 的概念。 NotebookNotebook Normal Equation使用 Matrix calculus上篇我們提到利用 Gradient descent 迭代多次求得最佳解（仍可">
<meta property="og:type" content="article">
<meta property="og:title" content="[Series - 14] Regression - 3">
<meta property="og:url" content="http://justin900429.github.io/2020/09/01/it/it-14/index.html">
<meta property="og:site_name" content="Justin">
<meta property="og:description" content="[Series - 14] Regression - 3See moreBack to the series page   前言今天會延續上篇的部分，繼續做一些推導，並且引進 Maximun likelihood 的概念。 NotebookNotebook Normal Equation使用 Matrix calculus上篇我們提到利用 Gradient descent 迭代多次求得最佳解（仍可">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.imgur.com/H5jTh5Q.jpg">
<meta property="og:image" content="https://i.imgur.com/8qVtqEG.jpg">
<meta property="og:image" content="https://fabiandablander.com/assets/img/2019-01-11-Curve-Fitting-Gaussian.Rmd/unnamed-chunk-9-1.png">
<meta property="article:published_time" content="2020-09-01T13:52:29.000Z">
<meta property="article:modified_time" content="2020-12-12T04:28:38.082Z">
<meta property="article:author" content="Justin Ruan">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://i.imgur.com/H5jTh5Q.jpg">


    
<link rel="stylesheet" href="/css/style/main.css">
 



    
    
    
        <link rel="stylesheet" id="hl-default-theme" href="https://cdn.jsdelivr.net/npm/highlight.js@10.1.2/styles/atom-one-light.min.css" media="none" onload="if(getComputedStyle(document.documentElement).getPropertyValue('--color-mode').indexOf('dark')===-1)this.media='all'">
        
    

    

    
    <link rel="stylesheet" href="/css/style/note.css" media="none" onload="this.media='all'">


     

    <!-- custom head -->

<meta name="generator" content="Hexo 5.1.1"></head>

    <body>
        <div id="app">
            <header class="header">
    <div class="header__left">
        <a href="/" class="button">
            <span class="logo__text">
                Justin's blog
            </span>
        </a>
    </div>
    <div class="header__right">
        
            <div class="navbar__menus">
                
                    <a href="/about/" class="navbar-menu button">
                        Home
                    </a>
                
                    <a href="/" class="navbar-menu button">
                        Articles
                    </a>
                
                    <a href="/tags/" class="navbar-menu button">
                        Tags
                    </a>
                
                    <a href="/archives/" class="navbar-menu button">
                        Archives
                    </a>
                
            </div>
        
        
        
    <a href="/search/" id="btn-search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="24" height="24" fill="currentColor" stroke="currentColor" stroke-width="32"><path d="M192 448c0-141.152 114.848-256 256-256s256 114.848 256 256-114.848 256-256 256-256-114.848-256-256z m710.624 409.376l-206.88-206.88A318.784 318.784 0 0 0 768 448c0-176.736-143.264-320-320-320S128 271.264 128 448s143.264 320 320 320a318.784 318.784 0 0 0 202.496-72.256l206.88 206.88 45.248-45.248z"></path></svg>
    </a>


        
        

         
    <a href="javaScript:void(0);" id="b2t" aria-label="Back to Top" title="Back to Top">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width='32' height='32' fill="currentColor" stroke="currentColor" stroke-width="0.7" stroke-linecap="round" stroke-linejoin="round">
            <path d="M13.889,11.611c-0.17,0.17-0.443,0.17-0.612,0l-3.189-3.187l-3.363,3.36c-0.171,0.171-0.441,0.171-0.612,0c-0.172-0.169-0.172-0.443,0-0.611l3.667-3.669c0.17-0.17,0.445-0.172,0.614,0l3.496,3.493C14.058,11.167,14.061,11.443,13.889,11.611 M18.25,10c0,4.558-3.693,8.25-8.25,8.25c-4.557,0-8.25-3.692-8.25-8.25c0-4.557,3.693-8.25,8.25-8.25C14.557,1.75,18.25,5.443,18.25,10 M17.383,10c0-4.07-3.312-7.382-7.383-7.382S2.618,5.93,2.618,10S5.93,17.381,10,17.381S17.383,14.07,17.383,10"></path>
        </svg>
    </a>


        
            <a class="dropdown-icon button" id="btn-dropdown">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width='24' height='24' fill="none" stroke="currentColor" stroke-width="0.7" stroke-linecap="round" stroke-linejoin="round">
                    <path fill="currentColor" d="M3.314,4.8h13.372c0.41,0,0.743-0.333,0.743-0.743c0-0.41-0.333-0.743-0.743-0.743H3.314c-0.41,0-0.743,0.333-0.743,0.743C2.571,4.467,2.904,4.8,3.314,4.8z M16.686,15.2H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,15.2,16.686,15.2z M16.686,9.257H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,9.257,16.686,9.257z"></path>
                </svg>
            </a>
            <div class="dropdown-menus" id="dropdown-menus">
                <a class="dropback-icon button" id="btn-dropback">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width='24' height='24' fill="none" stroke="currentColor" stroke-width="0.7" stroke-linecap="round" stroke-linejoin="round">
                        <path fill="currentColor" d="M11.469,10l7.08-7.08c0.406-0.406,0.406-1.064,0-1.469c-0.406-0.406-1.063-0.406-1.469,0L10,8.53l-7.081-7.08c-0.406-0.406-1.064-0.406-1.469,0c-0.406,0.406-0.406,1.063,0,1.469L8.531,10L1.45,17.081c-0.406,0.406-0.406,1.064,0,1.469c0.203,0.203,0.469,0.304,0.735,0.304c0.266,0,0.531-0.101,0.735-0.304L10,11.469l7.08,7.081c0.203,0.203,0.469,0.304,0.735,0.304c0.267,0,0.532-0.101,0.735-0.304c0.406-0.406,0.406-1.064,0-1.469L11.469,10z"></path>
                    </svg>
                </a>
                
                    <a href="/about/" class="dropdown-menu button">
                        Home
                    </a>
                
                    <a href="/" class="dropdown-menu button">
                        Articles
                    </a>
                
                    <a href="/tags/" class="dropdown-menu button">
                        Tags
                    </a>
                
                    <a href="/archives/" class="dropdown-menu button">
                        Archives
                    </a>
                
            </div>
            <script>
                document.getElementById('btn-dropdown').addEventListener('click', () => {
                    const dd = document.getElementById('dropdown-menus');
                    requestAnimationFrame(() => {
                        dd.style.display = 'flex';
                        requestAnimationFrame(() => {
                            dd.style.transform = 'translateY(0)';
                            dd.style.opacity = '1';
                        });
                    });
                });
                document.getElementById('btn-dropback').addEventListener('click', () => {
                    const dd = document.getElementById('dropdown-menus');
                    dd.style.transform = 'translateY(2.25rem)';                    
                    dd.style.opacity = '0';
                    setTimeout(() => {dd.style.display = 'none';}, 350);
                });
            </script>
        
    </div>
</header>


            <main class="main">
    
<div class="post-title">
    <h1 class="post-title__text">
        [Series - 14] Regression - 3
    </h1>
    <div class="post-title__meta">
        <a href="/archives/2020/09/" class="post-meta__date button">
    2020-09-01
</a>
        
 
        
    
    


 

 
    </div>
</div>


    <div class="post__with-side">
        <aside class="post-side">
            <div class="post-side__toc">
                <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Notebook"><span class="toc-number">2.</span> <span class="toc-text">Notebook</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Normal-Equation"><span class="toc-number">3.</span> <span class="toc-text">Normal Equation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-Matrix-calculus"><span class="toc-number">3.1.</span> <span class="toc-text">使用 Matrix calculus</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-Projection-matrix"><span class="toc-number">3.2.</span> <span class="toc-text">使用 Projection matrix</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Normal-equation-%E7%A8%8B%E5%BC%8F%E7%A2%BC"><span class="toc-number">3.3.</span> <span class="toc-text">Normal equation 程式碼</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maxmimun-likelihood"><span class="toc-number">4.</span> <span class="toc-text">Maxmimun likelihood</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E9%BA%BC%E6%98%AF-Maximum-likelihood"><span class="toc-number">4.1.</span> <span class="toc-text">什麼是 Maximum likelihood?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Regression-%E7%9A%84%E6%A9%9F%E7%8E%87%E5%90%AB%E7%BE%A9"><span class="toc-number">4.2.</span> <span class="toc-text">Regression 的機率含義</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%B5%90"><span class="toc-number">5.</span> <span class="toc-text">小結</span></a></li></ol>
            </div>
        </aside>
        <article class="post content-card">
            <div class="post__header"></div>
            <div class="post__content">
                <h1 id="Series-14-Regression-3"><a href="#Series-14-Regression-3" class="headerlink" title="[Series - 14] Regression - 3"></a>[Series - 14] Regression - 3</h1><blockquote class="blockquote-note blockquote-note__tip"><div class="blockquote-note__header"><div class="blockquote-note__icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></div>See more</div><div class="blockquote-note__content"><p><a href="/2020/08/29/it/it-series/">Back to the series page</a></p>
</div></blockquote>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天會延續上篇的部分，繼續做一些推導，並且引進 <strong>Maximun likelihood</strong> 的概念。</p>
<h2 id="Notebook"><a href="#Notebook" class="headerlink" title="Notebook"></a>Notebook</h2><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/Justin900429/IT-used/blob/master/Regression.ipynb">Notebook</a></p>
<h2 id="Normal-Equation"><a href="#Normal-Equation" class="headerlink" title="Normal Equation"></a>Normal Equation</h2><h3 id="使用-Matrix-calculus"><a href="#使用-Matrix-calculus" class="headerlink" title="使用 Matrix calculus"></a>使用 <strong>Matrix calculus</strong></h3><p>上篇我們提到利用 <strong>Gradient descent</strong> 迭代多次求得最佳解（仍可能有些誤差，但是經過多次誤差可以逼近0)，這篇我們要說明另一個方式一次就找到最佳解 - <strong>Normal Equation</strong>。但是這需要用到矩陣微積分，這邊我就不另外提了，有興趣可以看<a target="_blank" rel="noopener" href="https://explained.ai/matrix-calculus/">這裡</a>!</p>
<p>假設我們有 $n$ 個 features，$m$ 筆資料，我們X矩陣就可以寫成這樣：</p>
<p>$$<br>X =<br>\begin{pmatrix}<br>(x^{(1)})^T \\<br>(x^{(2)})^T \\<br>\vdots \\<br>(x^{(m)})^T \\<br>\end{pmatrix}<br>where \ x^{(i)} \in R^n<br>$$</p>
<p>因此我們對應的 $y$ 可以寫成：</p>
<p>$$<br>\vec{y} =<br>\begin{pmatrix}<br>y^{(1)} \\<br>y^{(2)} \\<br>\vdots \\<br>y^{(m)} \\<br>\end{pmatrix}<br>$$</p>
<p><strong>Loss function</strong> 是：</p>
<p>$$<br>\begin{align}<br>  \\\\<br>  J(\theta) &amp;= \frac{1}{2m}\sum_{i=1}^{m}\mid\mid h_\theta(x^{(i)}) - y^{(i)} \mid\mid^2 \\\\<br>  &amp;= \frac{1}{2m}(X\theta - \vec{y})^T(X\theta - \vec{y})<br>  \\\\<br>\end{align}<br>$$</p>
<p>直接對 <strong>Loss function</strong>微分：</p>
<p>$$<br>\begin{align}<br>  \nabla J(\theta) &amp;= \nabla _\theta \frac{1}{2m}(X\theta - \vec{y})^T(X\theta - \vec{y}) \\\\<br>  &amp;= \frac{1}{2m} \nabla _\theta ((X\theta)^T X\theta - (X\theta)^T\vec{y} - \vec{y}^T(X\theta) + \vec{y}^T\vec{y}) \\\\<br>  &amp;= \frac{1}{2m} \nabla _\theta (\theta^T X^T X\theta - \vec{y}^T(X\theta) - \vec{y}^T(X\theta)) + \frac{1}{2m}\nabla _\theta(\vec{y}^T\vec{y}) \\\\<br>  &amp;= \frac{1}{2m} \nabla _\theta (\theta^T X^T X\theta - 2\vec{y}^T(X\theta))  + \frac{1}{2m} * 0 \\\\<br>  &amp;= \frac{1}{2m} \nabla _\theta (\theta^T (X^T X)\theta - 2(X^T \vec{y})^T\theta) \\\\<br>  &amp;= \frac{1}{2m}(2X^TX\theta - 2X^T\vec{y}) \\\\<br>  &amp;= X^TX\theta - X^T\vec{y}<br>\end{align}<br>$$</p>
<p>現在我們另<strong>Loss function</strong> 等於 $0$ 解極值：</p>
<p>$$<br>\begin{align}<br>\\<br>\nabla J_\theta &amp;= \frac{1}{m}(X^TX\theta - X^T\vec{y}) = 0 \\\\<br>X^TX\theta &amp;= X^Ty \\\\<br>\theta &amp;= (X^TX)^{-1}X^T y<br>\end{align}<br>$$</p>
<h3 id="使用-Projection-matrix"><a href="#使用-Projection-matrix" class="headerlink" title="使用 Projection matrix"></a>使用 Projection matrix</h3><p>我們可以想像每一個 $x^{(i)}$ 存在於一個平面$W$（高維的平面），而 $X$ 是所有資料的組成矩陣，因此 $X\theta \in W  \ ，\forall \theta \in R^n$。而我們所得到的 label 並沒有存在於 $W$（不然我們就可以直接找到平面通過所有點了！）我們的目標就是找到 $\theta$ 使得 $\mid\mid \vec{y} - X\theta \mid\mid$最小，下圖應該會更清楚：</p>
<p><img src="https://i.imgur.com/H5jTh5Q.jpg" class="lazyload" data-srcset="https://i.imgur.com/H5jTh5Q.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg=="></p>
<p>想要找到最距離，就是要找到 $\vec{y}$ 投影到 $W$ 的向量 $\vec{y}_ p$，因為 $\vec{y}_ p\in W$ ，所以 $\vec{y}_ p$ 可以表示成 $X\theta$，又 $\vec{y} - \vec{y_ p} \in Null(W)$，因此我們可以寫出以下算示：</p>
<p>$$<br>\begin{align}<br>  \\\\<br>  X^T(\vec{y} - X\theta) &amp;= 0 \\\\<br>  X^T X \theta &amp;= X^T\vec{y} \\\\<br>  \theta &amp;= (X^TX)^{-1}X^T y<br>\end{align}<br>$$</p>
<h3 id="Normal-equation-程式碼"><a href="#Normal-equation-程式碼" class="headerlink" title="Normal equation 程式碼"></a>Normal equation 程式碼</h3><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">normal_eqn</span>(<span class="hljs-params">X, y</span>):</span>
    <span class="hljs-string">&#x27;&#x27;&#x27;</span>
<span class="hljs-string">    Input:</span>
<span class="hljs-string">        X: data (2D array)</span>
<span class="hljs-string">        y: labels (1D array)</span>
<span class="hljs-string">    </span>
<span class="hljs-string">    Use: </span>
<span class="hljs-string">        Return \theta by normal equation</span>
<span class="hljs-string">    </span>
<span class="hljs-string">    Output</span>
<span class="hljs-string">        theta: param for regression (1D array)</span>
<span class="hljs-string">    &#x27;&#x27;&#x27;</span>

    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)
    <span class="hljs-keyword">return</span> theta</code></pre>

<p><img src="https://i.imgur.com/8qVtqEG.jpg" class="lazyload" data-srcset="https://i.imgur.com/8qVtqEG.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg=="></p>
<h2 id="Maxmimun-likelihood"><a href="#Maxmimun-likelihood" class="headerlink" title="Maxmimun likelihood"></a>Maxmimun likelihood</h2><h3 id="什麼是-Maximum-likelihood"><a href="#什麼是-Maximum-likelihood" class="headerlink" title="什麼是 Maximum likelihood?"></a>什麼是 Maximum likelihood?</h3><p><strong>Likelihood</strong> 想要敘述的就是給定所以 $x$ 他對應 $y$ 的機率乘積是多少，數學形式是（$\theta$ 為參數）：</p>
<p>$$<br>Likelihood: \ L(\theta) = \prod_{i=1}^{m}p(y^{(i)} \mid x^{(i)}; \theta)<br>$$</p>
<p>而<strong>Maximum Likelihood</strong> 想要表達就是找到 $\theta$，使得所有<strong>Likelihood</strong> 的乘積最大：</p>
<p>$$<br>Maximum \ Likelihood: \ \underset{\theta}{\operatorname{argmax}}L(\theta)<br>$$</p>
<h3 id="Regression-的機率含義"><a href="#Regression-的機率含義" class="headerlink" title="Regression 的機率含義"></a>Regression 的機率含義</h3><p>其實我們在用 <strong>Regression</strong> 的時候，都是認為<strong>各資料點都是高斯分佈</strong>。</p>
<center><img src="https://fabiandablander.com/assets/img/2019-01-11-Curve-Fitting-Gaussian.Rmd/unnamed-chunk-9-1.png" class="lazyload" data-srcset="https://fabiandablander.com/assets/img/2019-01-11-Curve-Fitting-Gaussian.Rmd/unnamed-chunk-9-1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg=="/></center> <br><br>

<p>因此每點資料點都是:</p>
<p>$$<br>y^{(i)} = \theta^Tx^{(i)} + \epsilon^{(i)}<br>$$</p>
<p>其中 $\epsilon^{(i)} \sim N(0, \sigma^2)$，因此：</p>
<p>$$<br>p(\epsilon^{(i)}) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(\epsilon^{(i)})^2}{2\sigma^2})<br>$$</p>
<p>因為平移不影響標準差，只影響平均因此 $y^{(i)} \sim N(\theta^Tx^{(i)}, \sigma^2)$，因此我們可以推得:</p>
<p>$$<br>p(y^{(i)} \mid x^{(i)};\theta) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2})<br>$$</p>
<p>因此我們 <strong>Likelihood</strong> 就是：</p>
<p>$$<br>L(\theta) = \prod_{i=1}^{m}\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2})<br>$$</p>
<p>但因爲乘積實在很難做處理，因此我們都會取 $log$ 變成 <strong>Log likelihood</strong>：</p>
<p>$$<br>l(\theta) = log(L(\theta)) = \sum_{i=1}^{m}log\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2})<br>$$</p>
<p>所以當我們利用微分找 $l(\theta)$ 的最大值就是<strong>在找最佳解</strong>！但這邊我就不在多敘述了，有興趣的可以自己試試看，最後會發現就是在<strong>極小化 $J(\theta)$**。因此我在上上篇使用 **Gaussian</strong> 當雜訊就是因為這原因！</p>
<h2 id="小結"><a href="#小結" class="headerlink" title="小結"></a>小結</h2><p>今天我們講完了Regression有關的部分，如果有任何問題歡迎留言！下篇見！</p>
<br/>
<br/>
<a href="/2020/08/31/it/it-13" float=left>Last</a> <a href="/2020/09/03/it/it-15" style="float: right;">Next</a><!-- flag of hidden posts -->
            </div>
             
            <div class="post-footer__meta">
    <p>
        updated at 2020-12-12
    </p>
</div> 
            <div class="post-meta__cats">
    
    
</div> 
        </article>
        
            <div class="post__comments content-card" id="comment">
                
    <h4>Comments</h4>
    
    <div id="disqus_thread">Unable to load Disqus, please make sure your network can access.</div>

    
    
    
    
    
    
    
    


            </div>
        
    </div>


</main>

            <footer class="footer">
    
        <script src='https://cdnjs.cloudflare.com/ajax/libs/viz.js/1.7.1/viz.js'></script>
        <script>
          String.prototype.replaceAll = function(search, replacement) {
            var target = this;
            return target.split(search).join(replacement);
          };
      
          let vizObjects = document.querySelectorAll('.graphviz')
      
          for (let item of vizObjects) {
            let svg = undefined
            try {
              svg = Viz(item.textContent.replaceAll('–', '--'), 'svg')
            } catch(e) {
              svg = `<pre class="error">${e}</pre>`
            }
            item.outerHTML = svg
          }
        </script>
    
    


    
     
 

 
    
        
        <p class="footer-copyright">
            Copyright&nbsp;©&nbsp;2020&nbsp;<a href="/">Justin</a>
        </p>
    
    
    <p>Powered by <a href="https://hexo.io" target="_blank">Hexo</a> | Theme - <a href="https://github.com/ChrAlpha/hexo-theme-cards" target="_blank">Cards</a></p>
</footer>

        </div>
        
    <script defer src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
    <script>
        window.lazyLoadOptions = {
            elements_selector: ".lazyload",
            threshold: 0
        };
    </script>
 

 

 

 

  



 


    


 

 
    <script defer src="/js/b2t.js"></script>



    <script>
        if (typeof MathJax === 'undefined') {
            window.MathJax = {
                loader: {
                    source: {
                        '[tex]/amsCd': '[tex]/amscd',
                        '[tex]/AMScd': '[tex]/amscd'
                    }
                },
                tex: {
                    inlineMath: [['$', '$'], ['\\(', '\\)']],
                },
                options: {
                    renderActions: {
                        findScript: [10, doc => {
                            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                                const display = !!node.type.match(/; *mode=display/);
                                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                                const text = document.createTextNode('');
                                node.parentNode.replaceChild(text, node);
                                math.start = {node: text, delim: '', n: 0};
                                math.end = {node: text, delim: '', n: 0};
                                doc.math.push(math);
                            });
                        }, '', false],
                        insertedScript: [200, () => {
                            document.querySelectorAll('mjx-container').forEach(node => {
                                let target = node.parentNode;
                                if (target.nodeName.toLowerCase() === 'li') {
                                    target.parentNode.classList.add('has-jax');
                                }
                            });
                        }, '', false]
                    }
                }
            };
            (function () {
                var script = document.createElement('script');
                script.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
                script.defer = true;
                document.head.appendChild(script);
            })();
        } else {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
        }
    </script>



    
    <script>
        function loadComment() {
            window.disqus_config = function () {
                this.page.url = 'http://justin900429.github.io/2020/09/01/it/it-14/';
                this.page.identifier = '2020/09/01/it/it-14/';
            };
            (function(){
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + 'https-justin900429-github-io' + '.disqus.com/embed.js';
                (document.head || document.body).appendChild(dsq);
            })();
        }
    
        var runningOnBrowser = typeof window !== "undefined";
        var isBot = runningOnBrowser && !("onscroll" in window) || typeof navigator !== "undefined" && /(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent);
        var supportsIntersectionObserver = runningOnBrowser && "IntersectionObserver" in window;
    
        setTimeout(function () {
            if (!isBot && supportsIntersectionObserver) {
                var comment_observer = new IntersectionObserver(function(entries) {
                    if (entries[0].isIntersecting) {
                        loadComment();
                        comment_observer.disconnect();
                    }
                }, { threshold: [0] });
                comment_observer.observe(document.getElementById('comment'));
            } else {
                loadComment();
            }
        }, 1);
    </script>


    
    
    

    
    
    
    
    
    
    
    
    

    



    </body>
</html>
