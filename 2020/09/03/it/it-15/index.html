<!DOCTYPE html>
<html lang="en">
    <head>
    <meta charset="utf-8">

    

    <!-- 渲染优化 -->
    <meta name="renderer" content="webkit">
    <meta name="force-rendering" content="webkit">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="HandheldFriendly" content="True" >
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <!--icon-->

    
        <link rel="shortcut icon" href="/mylogo.ico">
    
    
    
    
    


    <!-- meta -->


<title>[Series - 15] Classification - Logistic Regression - 1 | Justin</title><meta name="robots" content="noindex">





    <!-- OpenGraph -->
 
    <meta name="description" content="[Series - 15] Classification - Logistic Regression - 1See moreBack to the series page   前言前幾篇都在介紹 Regression，接下來幾天換介紹 classification 中的 Logistic Regression 啦！同樣會分成應用跟理論篇，應用會在今天講解，剩下部分會留到下幾篇。 NotebookN">
<meta property="og:type" content="article">
<meta property="og:title" content="[Series - 15] Classification - Logistic Regression - 1">
<meta property="og:url" content="http://justin900429.github.io/2020/09/03/it/it-15/index.html">
<meta property="og:site_name" content="Justin">
<meta property="og:description" content="[Series - 15] Classification - Logistic Regression - 1See moreBack to the series page   前言前幾篇都在介紹 Regression，接下來幾天換介紹 classification 中的 Logistic Regression 啦！同樣會分成應用跟理論篇，應用會在今天講解，剩下部分會留到下幾篇。 NotebookN">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://static.javatpoint.com/tutorial/machine-learning/images/classification-algorithm-in-machine-learning.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Sigmoid-function-2.svg/1280px-Sigmoid-function-2.svg.png">
<meta property="og:image" content="https://i.imgur.com/3lXgDOP.jpg">
<meta property="article:published_time" content="2020-09-03T06:20:08.000Z">
<meta property="article:modified_time" content="2020-09-12T06:08:39.258Z">
<meta property="article:author" content="Justin Ruan">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://static.javatpoint.com/tutorial/machine-learning/images/classification-algorithm-in-machine-learning.png">


    
<link rel="stylesheet" href="/css/style/main.css">
 



    
    
    
        <link rel="stylesheet" id="hl-default-theme" href="https://cdn.jsdelivr.net/npm/highlight.js@10.1.2/styles/atom-one-light.min.css" media="none" onload="if(getComputedStyle(document.documentElement).getPropertyValue('--color-mode').indexOf('dark')===-1)this.media='all'">
        
    

    

     

    <!-- custom head -->

<meta name="generator" content="Hexo 5.1.1"></head>

    <body>
        <div id="app">
            <header class="header">
    <div class="header__left">
        <a href="/" class="button">
            <span class="logo__text">Justin&#39;s blog</span>
        </a>
    </div>
    <div class="header__right">
        
            <div class="navbar__menus">
                
                    <a href="/about/" class="navbar-menu button">Home</a>
                
                    <a href="/about/resume.pdf" class="navbar-menu button">CV</a>
                
                    <a href="/" class="navbar-menu button">Articles</a>
                
                    <a href="/tags/" class="navbar-menu button">Tags</a>
                
                    <a href="/archives/" class="navbar-menu button">Archives</a>
                
            </div>
        
        
        
    <a href="/search/" id="btn-search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="24" height="24" fill="currentColor" stroke="currentColor" stroke-width="32"><path d="M192 448c0-141.152 114.848-256 256-256s256 114.848 256 256-114.848 256-256 256-256-114.848-256-256z m710.624 409.376l-206.88-206.88A318.784 318.784 0 0 0 768 448c0-176.736-143.264-320-320-320S128 271.264 128 448s143.264 320 320 320a318.784 318.784 0 0 0 202.496-72.256l206.88 206.88 45.248-45.248z"></path></svg>
    </a>


        
        

         
    <a href="#" class="button" id="b2t" aria-label="Back to Top" title="Back to Top">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="32" height="32">
            <path d="M233.376 722.752L278.624 768 512 534.624 745.376 768l45.248-45.248L512 444.128zM192 352h640V288H192z" fill="currentColor"></path>
        </svg>
    </a>


        
            <a class="dropdown-icon button" id="btn-dropdown" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width='24' height='24' fill="none" stroke="currentColor" stroke-width="0.7" stroke-linecap="round" stroke-linejoin="round"><path fill="currentColor" d="M3.314,4.8h13.372c0.41,0,0.743-0.333,0.743-0.743c0-0.41-0.333-0.743-0.743-0.743H3.314c-0.41,0-0.743,0.333-0.743,0.743C2.571,4.467,2.904,4.8,3.314,4.8z M16.686,15.2H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,15.2,16.686,15.2z M16.686,9.257H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,9.257,16.686,9.257z"></path></svg></a>
            <div class="dropdown-menus" id="dropdown-menus">
                
                    <a href="/about/" class="dropdown-menu button">Home</a>
                
                    <a href="/about/resume.pdf" class="dropdown-menu button">CV</a>
                
                    <a href="/" class="dropdown-menu button">Articles</a>
                
                    <a href="/tags/" class="dropdown-menu button">Tags</a>
                
                    <a href="/archives/" class="dropdown-menu button">Archives</a>
                
            </div>
        
    </div>
</header>


            <main class="main">
    

<div class="post-title">
    <h1 class="post-title__text">
        [Series - 15] Classification - Logistic Regression - 1
    </h1>
    <div class="post-title__meta">
        <a href="/archives/2020/09/" class="post-meta__date button">2020-09-03</a>
        
 
        
    
    


 

 
    </div>
</div>


    <aside class="post-side">
        <div class="post-side__toc">
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Notebook"><span class="toc-number">2.</span> <span class="toc-text">Notebook</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E9%BA%BC%E6%98%AF-Classification"><span class="toc-number">3.</span> <span class="toc-text">什麼是 Classification?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Logistic-Regression"><span class="toc-number">4.</span> <span class="toc-text">Logistic Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BC%94%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.</span> <span class="toc-text">演算法流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sigmoid-function"><span class="toc-number">4.2.</span> <span class="toc-text">Sigmoid function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%9E%E8%88%87%E5%B9%B3%E9%9D%A2"><span class="toc-number">4.3.</span> <span class="toc-text">點與平面</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scikit-Learn"><span class="toc-number">5.</span> <span class="toc-text">Scikit Learn</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%B5%90"><span class="toc-number">6.</span> <span class="toc-text">小結</span></a></li></ol>
        </div>
    </aside>
    <a class="btn-toc button" id="btn-toc" tabindex="0">
        <svg viewBox="0 0 1024 1024" width="32" height="32" xmlns="http://www.w3.org/2000/svg">
            <path d="M128 256h64V192H128zM320 256h576V192H320zM128 544h64v-64H128zM320 544h576v-64H320zM128 832h64v-64H128zM320 832h576v-64H320z" fill="currentColor"></path>
        </svg>
    </a>
    <div class="toc-menus" id="toc-menus">
        <div class="toc-title">Article Directory</div>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Notebook"><span class="toc-number">2.</span> <span class="toc-text">Notebook</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E9%BA%BC%E6%98%AF-Classification"><span class="toc-number">3.</span> <span class="toc-text">什麼是 Classification?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Logistic-Regression"><span class="toc-number">4.</span> <span class="toc-text">Logistic Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BC%94%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.</span> <span class="toc-text">演算法流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sigmoid-function"><span class="toc-number">4.2.</span> <span class="toc-text">Sigmoid function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%9E%E8%88%87%E5%B9%B3%E9%9D%A2"><span class="toc-number">4.3.</span> <span class="toc-text">點與平面</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scikit-Learn"><span class="toc-number">5.</span> <span class="toc-text">Scikit Learn</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%B5%90"><span class="toc-number">6.</span> <span class="toc-text">小結</span></a></li></ol>
    </div>


<article class="post content-card">
    <div class="post__header"></div>
    <div class="post__content">
        <h1 id="Series-15-Classification-Logistic-Regression-1"><a href="#Series-15-Classification-Logistic-Regression-1" class="headerlink" title="[Series - 15] Classification - Logistic Regression - 1"></a>[Series - 15] Classification - Logistic Regression - 1</h1><blockquote class="blockquote-note blockquote-note__tip"><div class="blockquote-note__header"><div class="blockquote-note__icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></div>See more</div><div class="blockquote-note__content"><p><a href="/2020/08/29/it/it-series/">Back to the series page</a></p>
</div></blockquote>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前幾篇都在介紹 <strong>Regression</strong>，接下來幾天換介紹 <strong>classification</strong> 中的 <strong>Logistic Regression</strong> 啦！同樣會分成應用跟理論篇，應用會在今天講解，剩下部分會留到下幾篇。</p>
<h2 id="Notebook"><a href="#Notebook" class="headerlink" title="Notebook"></a>Notebook</h2><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/Justin900429/IT-used/blob/master/Logistic%20Regression.ipynb">Notebook</a></p>
<h2 id="什麼是-Classification"><a href="#什麼是-Classification" class="headerlink" title="什麼是 Classification?"></a>什麼是 Classification?</h2><p><strong>Classification</strong>就是利用已知的資料做分類，一般都是做二元分類，就是指區分有跟沒有。例如：有吃飯跟沒吃飯、是狗或是貓（貓就是不是狗）等等… 另外，我們也習慣把<strong>有設定成1</strong>，<strong>沒有設定成0</strong>。</p>
<p><img src="https://static.javatpoint.com/tutorial/machine-learning/images/classification-algorithm-in-machine-learning.png"></p>
<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><h3 id="演算法流程"><a href="#演算法流程" class="headerlink" title="演算法流程"></a>演算法流程</h3><p><strong>Logistic Regression</strong>。就是一種實現 <strong>Classification</strong> 的演算法。他的想法就是先找到一條直線，使得資料可以分成在<strong>線的兩邊</strong>（如果是高維則是面的兩邊）。之後再利用 <strong>sigmoid function</strong> 來判別各點類別的機率，並加以做分類。流程圖是：</p>
<ol>
<li>利用平面將資料點分成兩類</li>
<li>利用 <strong>Sigmoid function</strong> 得到機率</li>
<li>利用機率來做分類</li>
</ol>
<h3 id="Sigmoid-function"><a href="#Sigmoid-function" class="headerlink" title="Sigmoid function"></a>Sigmoid function</h3><p><strong>Sigmoid function</strong> 函數的面貌是：</p>
<p>$$<br>g(x) = \frac{1}{1 + e^{-x}}<br>$$</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Sigmoid-function-2.svg/1280px-Sigmoid-function-2.svg.png"></p>
<p><strong>Sigmoid</strong> 有下列特性:</p>
<p>$$<br>\\<br>\begin{align}<br>(1)&amp;: \ g(0) = 0.5 \\\\<br>(2)&amp;: \ 0 \lt g(x) \lt 1 \\\\<br>(3)&amp;: \lim_{x\to\infty}g(x) = 1 \\\\<br>(4)&amp;: \lim_{x\to -\infty}g(x) = 0<br>\end{align}<br>$$</p>
<p>由上面的性質我們可以知道 <strong>Sigmoid</strong> 扮演很好的分類函數，當我們用直線(平面)將資料分成兩類時，一邊將值帶入可以得到大於 0 的數，另一邊則會得到小於 0 的數，之後取 <strong>sigmoid</strong> 後，當大於 0 是 1 的機率就大於 0.5，小於 0 是 1 的機率就小於 0.5 （代表是 0 的機率就大於 0.5），此時我們就可以用 <strong>Maximum likelihood</strong> 的方式找到優化的方式！(一般我們都會省略在線上的點)</p>
<p>$$<br>\begin{cases}<br>  g(\theta^TX) \gt 0.5, &amp; \text{if}\ \theta^TX &gt; 0 \\<br>  g(\theta^TX) \lt 0.5, &amp; \text{otherwise}<br>\end{cases}<br>$$</p>
<h3 id="點與平面"><a href="#點與平面" class="headerlink" title="點與平面"></a>點與平面</h3><p>當我們利用 $\theta^TX$ 取得某個值的時候，我們知道其值的絕對值愈大，則距離平面愈遠！<strong>愈遠，則為某類的可能性愈大！</strong> 因此<strong>值愈負，其為0的機率愈大</strong>，相反<strong>值愈正，其為1的機率愈大</strong>，這些性質 <strong>sigmoid</strong> 都可以很好的詮釋出來！因此我們在利用<strong>Maximum likelihood</strong>訓練參數的時候，就是希望可以得到最大的機率乘積！ 至於更細節的東西我們留到下篇說！</p>
<h2 id="Scikit-Learn"><a href="#Scikit-Learn" class="headerlink" title="Scikit Learn"></a>Scikit Learn</h2><p>我們現在就來看看如何使用 <strong>Sciki-learn</strong> 的套件做 <strong>Logistic Regression</strong> 吧！</p>
<p>先載入 sklearn 的內建資料集，這邊我們載入的是判斷有沒有癌症的二元分類資料集（有關乳癌的）。這邊我只挑兩個特徵（總共有 30 個，但有些並非獨立特徵），因為這樣才有視覺化的圖案可以做XD</p>
<pre><code class="hljs python"><span class="hljs-comment"># Load the breast dataset</span>
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets

data = datasets.load_breast_cancer()
breast_cancer = pd.DataFrame(data.data, columns=data.feature_names)

<span class="hljs-comment"># Just use only 2 features for demonstration</span>
breast_cancer = breast_cancer.loc[:, [<span class="hljs-string">&quot;mean radius&quot;</span>, <span class="hljs-string">&quot;mean compactness&quot;</span>]]

display(breast_cancer)</code></pre>
<br>

<p>之後做資料標準化，並根據有癌症跟沒有癌症做分類，並繪製出分類資料以及分類曲線</p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression

<span class="hljs-comment"># Standarize the data</span>
breast_cancer_std = StandardScaler().fit_transform(breast_cancer)

<span class="hljs-comment"># Fit the data</span>
model = LogisticRegression().fit(breast_cancer_std, data.target)
<span class="hljs-comment"># Accuracy of the model</span>
print(<span class="hljs-string">f&quot;The accuracy of the model is <span class="hljs-subst">&#123;model.score(breast_cancer_std, data.target)&#125;</span>&quot;</span>)

<span class="hljs-comment"># Plot the result</span>
plt.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>))
plt.xlim(<span class="hljs-number">-2.5</span>, <span class="hljs-number">4</span>)
plt.ylim(<span class="hljs-number">-2</span>, <span class="hljs-number">4</span>)

<span class="hljs-comment"># Plot the data point</span>
plt.scatter(breast_cancer_std[data.target == <span class="hljs-number">1</span>, <span class="hljs-number">0</span>], 
            breast_cancer_std[data.target == <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], 
            c=<span class="hljs-string">&quot;red&quot;</span>, label=<span class="hljs-string">&quot;positive&quot;</span>)

plt.scatter(breast_cancer_std[data.target == <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
            breast_cancer_std[data.target == <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], 
            c=<span class="hljs-string">&quot;blue&quot;</span>, label=<span class="hljs-string">&quot;negative&quot;</span>)

<span class="hljs-comment"># Plot the seperate plane</span>
x = np.arange(<span class="hljs-number">-2</span>, <span class="hljs-number">5</span>)
plt.plot(x, x * model.coef_[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] + model.coef_[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>], 
         label=<span class="hljs-string">&quot;seperation line&quot;</span>)

plt.legend(prop=&#123;<span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">15</span>&#125;)</code></pre>


<p><img src="https://i.imgur.com/3lXgDOP.jpg"></p>
<p><code>model</code> 裡還有很多<strong>attribute</strong> 可以用，我上面所使用的 <strong>model._coef</strong> 就是 $\theta$ 的參數。</p>
<p>我們也可以看看機率跟 <strong>label</strong> 的關係，這邊我們就挑第20到第24筆來看吧：</p>
<pre><code class="hljs python">result = zip(model.predict(breast_cancer_std[<span class="hljs-number">20</span>:<span class="hljs-number">25</span>]),
          model.predict_proba(breast_cancer_std[<span class="hljs-number">20</span>:<span class="hljs-number">25</span>])[:, <span class="hljs-number">1</span>])

<span class="hljs-keyword">for</span> count, (class_, prob) <span class="hljs-keyword">in</span> enumerate(result):
    print(<span class="hljs-string">f&quot;The correponding probability for label <span class="hljs-subst">&#123;class_&#125;</span> of <span class="hljs-subst">&#123;count&#125;</span>th object is <span class="hljs-subst">&#123;prob&#125;</span>.\n&quot;</span>)</code></pre>

<pre><code class="hljs python"><span class="hljs-comment"># output</span>

The correponding probability <span class="hljs-keyword">for</span> label <span class="hljs-number">1</span> of <span class="hljs-number">0</span>th object <span class="hljs-keyword">is</span> <span class="hljs-number">0.7246190930101648</span>.

The correponding probability <span class="hljs-keyword">for</span> label <span class="hljs-number">1</span> of <span class="hljs-number">1</span>th object <span class="hljs-keyword">is</span> <span class="hljs-number">0.9974729565670527</span>.

The correponding probability <span class="hljs-keyword">for</span> label <span class="hljs-number">0</span> of <span class="hljs-number">2</span>th object <span class="hljs-keyword">is</span> <span class="hljs-number">0.026303453790521614</span>.

The correponding probability <span class="hljs-keyword">for</span> label <span class="hljs-number">0</span> of <span class="hljs-number">3</span>th object <span class="hljs-keyword">is</span> <span class="hljs-number">0.004397432135645482</span>.

The correponding probability <span class="hljs-keyword">for</span> label <span class="hljs-number">0</span> of <span class="hljs-number">4</span>th object <span class="hljs-keyword">is</span> <span class="hljs-number">0.0605503698769022</span>.</code></pre>

<p>透過上面的觀察，$\gt 0.5$ 都被分配到 $1$，$\lt 0.5$ 都被分配到 0。</p>
<h2 id="小結"><a href="#小結" class="headerlink" title="小結"></a>小結</h2><p>今天我們介紹完 <strong>Classification</strong> 的概念，也講完 <strong>Logistic Regression</strong> 的應用，下篇一樣會開始討論背後的數學！</p>
<br/>
<br/>
<a href="/2020/09/01/it/it-14" float=left>Last</a> <a href="/2020/09/04/it/it-16" style="float: right;">Next</a><!-- flag of hidden posts -->
    </div>
     
    <div class="post-footer__meta"><p>updated at 2020-09-12</p></div> 
    <div class="post-meta__cats"></div> 
</article>




    <div class="post__comments content-card" id="comment">
        
    <h4>Comments</h4>
    
    <div id="disqus_thread">Unable to load Disqus, please make sure your network can access.</div>

    
    
    
    
    
    
    
    
    


    </div>



</main>

            <footer class="footer">
    
        <script src='https://cdnjs.cloudflare.com/ajax/libs/viz.js/1.7.1/viz.js'></script>
        <script>
          String.prototype.replaceAll = function(search, replacement) {
            var target = this;
            return target.split(search).join(replacement);
          };
      
          let vizObjects = document.querySelectorAll('.graphviz')
      
          for (let item of vizObjects) {
            let svg = undefined
            try {
              svg = Viz(item.textContent.replaceAll('–', '--'), 'svg')
            } catch(e) {
              svg = `<pre class="error">${e}</pre>`
            }
            item.outerHTML = svg
          }
        </script>
    
    


    
     
 

 
    
        
        <p class="footer-copyright">
            Copyright © 2020 <a href="/">Justin</a>
        </p>
    
    
    <p>Powered by <a href="https://hexo.io" target="_blank">Hexo</a> | Theme - <a href="https://github.com/ChrAlpha/hexo-theme-cards" target="_blank">Cards</a></p>
</footer>

        </div>
         

 

 

 

  



 


    
 

 


    <script>
        if (typeof MathJax === 'undefined') {
            window.MathJax = {
                loader: {
                    source: {
                        '[tex]/amsCd': '[tex]/amscd',
                        '[tex]/AMScd': '[tex]/amscd'
                    }
                },
                tex: {
                    inlineMath: [['$', '$'], ['\\(', '\\)']],
                },
                options: {
                    renderActions: {
                        findScript: [10, doc => {
                            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                                const display = !!node.type.match(/; *mode=display/);
                                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                                const text = document.createTextNode('');
                                node.parentNode.replaceChild(text, node);
                                math.start = {node: text, delim: '', n: 0};
                                math.end = {node: text, delim: '', n: 0};
                                doc.math.push(math);
                            });
                        }, '', false],
                        insertedScript: [200, () => {
                            document.querySelectorAll('mjx-container').forEach(node => {
                                let target = node.parentNode;
                                if (target.nodeName.toLowerCase() === 'li') {
                                    target.parentNode.classList.add('has-jax');
                                }
                            });
                        }, '', false]
                    }
                }
            };
            (function () {
                var script = document.createElement('script');
                script.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
                script.defer = true;
                document.head.appendChild(script);
            })();
        } else {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
        }
    </script>
 

 

 


    
    <script>
        function loadComment() {
            window.disqus_config = function () {
                this.page.url = 'http://justin900429.github.io/2020/09/03/it/it-15/';
                this.page.identifier = '2020/09/03/it/it-15/';
            };
            (function(){
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + 'https-justin900429-github-io' + '.disqus.com/embed.js';
                (document.head || document.body).appendChild(dsq);
            })();
        }
    
        var runningOnBrowser = typeof window !== "undefined";
        var isBot = runningOnBrowser && !("onscroll" in window) || typeof navigator !== "undefined" && /(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent);
        var supportsIntersectionObserver = runningOnBrowser && "IntersectionObserver" in window;
    
        setTimeout(function () {
            if (!isBot && supportsIntersectionObserver) {
                var comment_observer = new IntersectionObserver(function(entries) {
                    if (entries[0].isIntersecting) {
                        loadComment();
                        comment_observer.disconnect();
                    }
                }, { threshold: [0] });
                comment_observer.observe(document.getElementById('comment'));
            } else {
                loadComment();
            }
        }, 1);
    </script>


    
    
    

    
    
    
    
    

    
    
    
    
    

    



    </body>
</html>
